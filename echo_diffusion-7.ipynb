{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec619f54-5dc4-4292-8727-066008d1e8ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec619f54-5dc4-4292-8727-066008d1e8ed",
    "outputId": "5b117faa-8a74-4912-bc05-093f2d4ba270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import necessary PyTorch libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    " \n",
    "# Set the device to MPS if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Additional libraries for visualization and utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a353550-e380-4555-8519-25b35c5b1654",
   "metadata": {
    "id": "8a353550-e380-4555-8519-25b35c5b1654"
   },
   "outputs": [],
   "source": [
    "# Import the adapted Echo noise functions\n",
    "from echo import echo_sample, echo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306efd2f-3f3b-418a-ab09-bf1173151f80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "306efd2f-3f3b-418a-ab09-bf1173151f80",
    "outputId": "807d84ee-b69b-4434-e510-e00e6a21255c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Data loaders created for training and validation.\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Grayscale\n",
    "\n",
    "# Define transformations: Convert to grayscale, resize if needed, and normalize the data\n",
    "transform = Compose([\n",
    "    Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    ToTensor(),\n",
    "    Normalize((0.5,), (0.5,))  # Normalize with single channel\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Splitting dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "print(\"Data loaders created for training and validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5860ada1-b1cb-45f5-accd-933906b45160",
   "metadata": {
    "id": "5860ada1-b1cb-45f5-accd-933906b45160"
   },
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dims):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_dims = latent_dims\n",
    "\n",
    "        self.unet = Unet(\n",
    "            encoder_name=\"resnet18\",\n",
    "            encoder_depth=3,\n",
    "            encoder_weights=None,\n",
    "            decoder_use_batchnorm=True,\n",
    "            decoder_channels=(latent_dims[2], latent_dims[1], latent_dims[0]),\n",
    "            decoder_attention_type=None,\n",
    "            in_channels=input_shape[0],\n",
    "            classes=latent_dims[-1],\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "        # Output layers\n",
    "        self.out_mean = nn.Conv2d(latent_dims[-1], input_shape[0], kernel_size=1)\n",
    "        self.out_log_var = nn.Conv2d(latent_dims[-1], input_shape[0], kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.unet(x)\n",
    "        f_x = torch.tanh(self.out_mean(x))\n",
    "        log_var = torch.sigmoid(self.out_log_var(x))\n",
    "        return f_x, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "TenNg_Ywlv3n",
   "metadata": {
    "id": "TenNg_Ywlv3n"
   },
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    This matches the implementation in Denoising Diffusion Probabilistic Models:\n",
    "    From Fairseq.\n",
    "    Build sinusoidal embeddings.\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = emb.to(device=timesteps.device)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = torch.nn.functional.pad(emb, (0,1,0,0))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f08a5ac-95ad-45ae-a36e-f96dbd3f1e99",
   "metadata": {
    "id": "1f08a5ac-95ad-45ae-a36e-f96dbd3f1e99"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims, output_shape, timestep_dim=128):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.latent_dims = latent_dims\n",
    "        self.output_shape = output_shape\n",
    "        self.timestep_dim = timestep_dim\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, latent_dims[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(latent_dims[0], latent_dims[1], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(latent_dims[1], latent_dims[2], kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(latent_dims[2], latent_dims[3], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(latent_dims[3], latent_dims[4], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.timestep_mlp = nn.Sequential(\n",
    "            nn.Linear(timestep_dim, latent_dims[4]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_dims[4], latent_dims[4]),\n",
    "        )\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(latent_dims[4] * 2, latent_dims[3], kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(latent_dims[3], latent_dims[2], kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(latent_dims[2], latent_dims[1], kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv4 = nn.ConvTranspose2d(latent_dims[1], latent_dims[0], kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv5 = nn.ConvTranspose2d(latent_dims[0], output_shape[0], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        timestep_emb = get_timestep_embedding(t, self.timestep_dim)\n",
    "        timestep_emb = self.timestep_mlp(timestep_emb)\n",
    "\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = torch.relu(self.conv5(x))\n",
    "\n",
    "        x = torch.cat([x, timestep_emb[:, :, None, None].repeat(1, 1, x.shape[2], x.shape[3])], dim=1)\n",
    "\n",
    "        x = torch.relu(self.deconv1(x))\n",
    "        x = torch.relu(self.deconv2(x))\n",
    "        x = torch.relu(self.deconv3(x))\n",
    "        x = torch.relu(self.deconv4(x))\n",
    "        x = torch.sigmoid(self.deconv5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77391b7-6374-4bb7-acd9-577f51a68706",
   "metadata": {
    "id": "a77391b7-6374-4bb7-acd9-577f51a68706"
   },
   "outputs": [],
   "source": [
    "class EchoModel(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dims, output_shape, T=1000, batch_size=100):\n",
    "        super(EchoModel, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_dims = latent_dims\n",
    "        self.output_shape = output_shape\n",
    "        self.T = T\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.encoder = Encoder(input_shape, latent_dims)\n",
    "        self.decoder = Decoder(latent_dims, output_shape)\n",
    "\n",
    "        # Define the noise schedule\n",
    "        self.alpha = self.create_noise_schedule(T)\n",
    "\n",
    "    def create_noise_schedule(self, T):\n",
    "        alpha = torch.linspace(0.9999, 1e-5, T)\n",
    "        return alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        f_x, sx_matrix = self.encoder(x)\n",
    "        # print(f\"Shape of fx: {f_x.shape}\")\n",
    "        # print(f\"Shape of Sx: {sx_matrix.shape}\")\n",
    "        # print(f\"Shape of input: {x.shape}\")\n",
    "        # assert(False)\n",
    "\n",
    "        # Convert log-variance to diagonal elements of S(x)\n",
    "        # diagonal_sx = torch.exp(log_var)\n",
    "\n",
    "        # Create the full square matrix representation of S(x)\n",
    "        # sx_matrix = torch.diag_embed(diagonal_sx)\n",
    "\n",
    "\n",
    "        # Generate the noise variable z using echo_sample\n",
    "        z = echo_sample([f_x, sx_matrix], d_max=99, batch_size=self.batch_size)\n",
    "        # print(f\"Shape of output: {z.shape}\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # print(f\"Shape of x: {x.shape}\")\n",
    "        # print(f\"Shape of z: {z.shape}\")\n",
    "        # alpha_T = self.alpha[-1]\n",
    "        # sqrt_alpha_T = torch.sqrt(alpha_T)\n",
    "        # sqrt_one_minus_alpha_T = torch.sqrt(1 - alpha_T)\n",
    "        # x_T = sqrt_alpha_T * x + sqrt_one_minus_alpha_T * z\n",
    "        alpha_T = self.alpha[-1]\n",
    "        sqrt_alpha_T = torch.sqrt(alpha_T)\n",
    "        sqrt_one_minus_alpha_T = torch.sqrt(1 - alpha_T)\n",
    "\n",
    "        # Reshape z for broadcasting: [100, 28] -> [100, 1, 28, 1]\n",
    "        # z_reshaped = z.unsqueeze(1).unsqueeze(-1)\n",
    "\n",
    "        # Repeat z across the spatial dimensions to match x's shape: [100, 1, 28, 1] -> [100, 1, 28, 28]\n",
    "        # z_broadcasted = z_reshaped.expand(-1, 1, x.shape[2], x.shape[3])\n",
    "\n",
    "        # Perform the weighted sum\n",
    "        x_T = sqrt_alpha_T * x + sqrt_one_minus_alpha_T * z\n",
    "\n",
    "\n",
    "        # Perform the reconstruction process using Algorithm 2\n",
    "        reconstructed_x = self.reconstruct(x_T, z, f_x, sx_matrix)\n",
    "        return reconstructed_x, f_x, sx_matrix\n",
    "\n",
    "    def reconstruct(self, x_t, z, f_x, sx_matrix):\n",
    "        x_s = x_t\n",
    "        for s in range(self.T-1, 0, -1):\n",
    "            t = torch.tensor([s] * x_t.size(0), dtype=torch.long).to(x_t.device)\n",
    "            sqrt_alpha_s = torch.sqrt(self.alpha[s])\n",
    "            sqrt_one_minus_alpha_s = torch.sqrt(1 - self.alpha[s])\n",
    "\n",
    "            # Estimate the original image using the decoder\n",
    "            x_0_hat = self.decoder(x_s, t)\n",
    "\n",
    "            # Calculate the estimated noise using Eq. (3)\n",
    "            z_hat = (x_s - sqrt_alpha_s * x_0_hat) / sqrt_one_minus_alpha_s\n",
    "\n",
    "            # Calculate D(x_0_hat, s) and D(x_0_hat, s-1) using Eq. (5) and (6)\n",
    "            D_x_0_hat_s = sqrt_alpha_s * x_0_hat + sqrt_one_minus_alpha_s * z_hat\n",
    "            D_x_0_hat_s_minus_1 = torch.sqrt(self.alpha[s-1]) * x_0_hat + torch.sqrt(1 - self.alpha[s-1]) * z_hat\n",
    "\n",
    "            # Update x_s using Eq. (7)\n",
    "            x_s = x_s - D_x_0_hat_s + D_x_0_hat_s_minus_1\n",
    "\n",
    "        return x_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c466c51d-3b41-4e11-bdfd-39b3d10ed2c9",
   "metadata": {
    "id": "c466c51d-3b41-4e11-bdfd-39b3d10ed2c9"
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import time  # Importing time to log the duration\n",
    "\n",
    "def train(model, optimizer, train_loader, device, num_epochs, loss_weights, accumulation_steps=2):\n",
    "    model.train()\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        optimizer.zero_grad()  # Move optimizer.zero_grad() outside the batch loop for gradient accumulation\n",
    "        epoch_start_time = time.time()  # Time tracking for the epoch\n",
    "\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            batch_start_time = time.time()  # Time tracking for the batch\n",
    "            data = data.to(device)\n",
    "\n",
    "            with autocast():  # Enable automatic mixed precision\n",
    "                reconstructed_x, f_x, sx_matrix = model(data)\n",
    "                # reconstruction_loss = nn.functional.l1_loss(reconstructed_x, data)\n",
    "                reconstruction_loss = nn.functional.mse_loss(reconstructed_x, data)\n",
    "                # mi_penalty = echo_loss([f_x, sx_matrix])\n",
    "                # total_loss = (loss_weights['reconstruction'] * reconstruction_loss + loss_weights['mi_penalty'] * mi_penalty) / accumulation_steps\n",
    "                total_loss = (loss_weights['reconstruction'] * reconstruction_loss) / accumulation_steps\n",
    "                print(f\"total loss: {total_loss}\")\n",
    "            # Log before the backward pass\n",
    "            print(f\"\\tBatch {batch_idx+1}/{len(train_loader)}, Forward pass done, starting backward pass.\")\n",
    "\n",
    "            # Scale the loss, but don't call optimizer.step() yet\n",
    "            scaler.scale(total_loss).backward()\n",
    "\n",
    "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                scaler.step(optimizer)  # Only step the optimizer every `accumulation_steps`\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()  # Reset gradients only after accumulation\n",
    "\n",
    "            print(f\"total loss item: {total_loss.item()}\")\n",
    "\n",
    "            epoch_loss += total_loss.item() * accumulation_steps  # Correct loss scaling after accumulation\n",
    "            print(f\"Epoch loss: {epoch_loss}\")\n",
    "\n",
    "            # Log after a batch is processed\n",
    "            print(f\"\\tBatch {batch_idx+1}/{len(train_loader)} processed in {time.time() - batch_start_time:.2f} seconds.\")\n",
    "\n",
    "        print(f\"Epoch loss accumulated: {epoch_loss}\")\n",
    "        print(f\"Train loader length as of now: {len(train_loader)}\")\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {time.time() - epoch_start_time:.2f} seconds, Avg Loss: {avg_loss}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ef76c-fb21-4fd4-b6e6-436524680219",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "661ef76c-fb21-4fd4-b6e6-436524680219",
    "outputId": "957794b4-bfe9-4884-ac9b-510743791893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/100\n",
      "total loss: nan\n",
      "\tBatch 1/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 1/400 processed in 6.07 seconds.\n",
      "total loss: nan\n",
      "\tBatch 2/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 2/400 processed in 6.23 seconds.\n",
      "total loss: nan\n",
      "\tBatch 3/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 3/400 processed in 6.33 seconds.\n",
      "total loss: nan\n",
      "\tBatch 4/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 4/400 processed in 6.40 seconds.\n",
      "total loss: nan\n",
      "\tBatch 5/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 5/400 processed in 6.32 seconds.\n",
      "total loss: nan\n",
      "\tBatch 6/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 6/400 processed in 6.28 seconds.\n",
      "total loss: nan\n",
      "\tBatch 7/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 7/400 processed in 6.45 seconds.\n",
      "total loss: nan\n",
      "\tBatch 8/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 8/400 processed in 6.31 seconds.\n",
      "total loss: nan\n",
      "\tBatch 9/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 9/400 processed in 6.29 seconds.\n",
      "total loss: nan\n",
      "\tBatch 10/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 10/400 processed in 6.28 seconds.\n",
      "total loss: nan\n",
      "\tBatch 11/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 11/400 processed in 6.31 seconds.\n",
      "total loss: nan\n",
      "\tBatch 12/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 12/400 processed in 6.33 seconds.\n",
      "total loss: nan\n",
      "\tBatch 13/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 13/400 processed in 6.38 seconds.\n",
      "total loss: nan\n",
      "\tBatch 14/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 14/400 processed in 6.35 seconds.\n",
      "total loss: nan\n",
      "\tBatch 15/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 15/400 processed in 6.52 seconds.\n",
      "total loss: nan\n",
      "\tBatch 16/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 16/400 processed in 6.27 seconds.\n",
      "total loss: nan\n",
      "\tBatch 17/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 17/400 processed in 6.26 seconds.\n",
      "total loss: nan\n",
      "\tBatch 18/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 18/400 processed in 6.39 seconds.\n",
      "total loss: nan\n",
      "\tBatch 19/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 19/400 processed in 6.26 seconds.\n",
      "total loss: nan\n",
      "\tBatch 20/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 20/400 processed in 6.28 seconds.\n",
      "total loss: nan\n",
      "\tBatch 21/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 21/400 processed in 6.27 seconds.\n",
      "total loss: nan\n",
      "\tBatch 22/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 22/400 processed in 6.36 seconds.\n",
      "total loss: nan\n",
      "\tBatch 23/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 23/400 processed in 6.38 seconds.\n",
      "total loss: nan\n",
      "\tBatch 24/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 24/400 processed in 6.36 seconds.\n",
      "total loss: nan\n",
      "\tBatch 25/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 25/400 processed in 6.34 seconds.\n",
      "total loss: nan\n",
      "\tBatch 26/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 26/400 processed in 6.45 seconds.\n",
      "total loss: nan\n",
      "\tBatch 27/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 27/400 processed in 6.29 seconds.\n",
      "total loss: nan\n",
      "\tBatch 28/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 28/400 processed in 6.36 seconds.\n",
      "total loss: nan\n",
      "\tBatch 29/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 29/400 processed in 6.40 seconds.\n",
      "total loss: nan\n",
      "\tBatch 30/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 30/400 processed in 6.28 seconds.\n",
      "total loss: nan\n",
      "\tBatch 31/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 31/400 processed in 6.27 seconds.\n",
      "total loss: nan\n",
      "\tBatch 32/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 32/400 processed in 6.42 seconds.\n",
      "total loss: nan\n",
      "\tBatch 33/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 33/400 processed in 6.27 seconds.\n",
      "total loss: nan\n",
      "\tBatch 34/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 34/400 processed in 6.56 seconds.\n",
      "total loss: nan\n",
      "\tBatch 35/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 35/400 processed in 6.38 seconds.\n",
      "total loss: nan\n",
      "\tBatch 36/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 36/400 processed in 6.34 seconds.\n",
      "total loss: nan\n",
      "\tBatch 37/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 37/400 processed in 6.39 seconds.\n",
      "total loss: nan\n",
      "\tBatch 38/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 38/400 processed in 6.35 seconds.\n",
      "total loss: nan\n",
      "\tBatch 39/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 39/400 processed in 6.29 seconds.\n",
      "total loss: nan\n",
      "\tBatch 40/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 40/400 processed in 6.33 seconds.\n",
      "total loss: nan\n",
      "\tBatch 41/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 41/400 processed in 6.26 seconds.\n",
      "total loss: nan\n",
      "\tBatch 42/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 42/400 processed in 6.26 seconds.\n",
      "total loss: nan\n",
      "\tBatch 43/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 43/400 processed in 6.47 seconds.\n",
      "total loss: nan\n",
      "\tBatch 44/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 44/400 processed in 6.32 seconds.\n",
      "total loss: nan\n",
      "\tBatch 45/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 45/400 processed in 6.35 seconds.\n",
      "total loss: nan\n",
      "\tBatch 46/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 46/400 processed in 6.41 seconds.\n",
      "total loss: nan\n",
      "\tBatch 47/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 47/400 processed in 6.33 seconds.\n",
      "total loss: nan\n",
      "\tBatch 48/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 48/400 processed in 6.27 seconds.\n",
      "total loss: nan\n",
      "\tBatch 49/400, Forward pass done, starting backward pass.\n",
      "total loss item: nan\n",
      "Epoch loss: nan\n",
      "\tBatch 49/400 processed in 6.28 seconds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m loss_weights \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreconstruction\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmi_penalty\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.0\u001b[39m}  \u001b[38;5;66;03m# Adjust the weights as needed\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, device, num_epochs, loss_weights, accumulation_steps)\u001b[0m\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():  \u001b[38;5;66;03m# Enable automatic mixed precision\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     reconstructed_x, f_x, sx_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# reconstruction_loss = nn.functional.l1_loss(reconstructed_x, data)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     reconstruction_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(reconstructed_x, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/parthaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/parthaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 60\u001b[0m, in \u001b[0;36mEchoModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m x_T \u001b[38;5;241m=\u001b[39m sqrt_alpha_T \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m+\u001b[39m sqrt_one_minus_alpha_T \u001b[38;5;241m*\u001b[39m z\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Perform the reconstruction process using Algorithm 2\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m reconstructed_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_T\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msx_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reconstructed_x, f_x, sx_matrix\n",
      "Cell \u001b[0;32mIn[7], line 71\u001b[0m, in \u001b[0;36mEchoModel.reconstruct\u001b[0;34m(self, x_t, z, f_x, sx_matrix)\u001b[0m\n\u001b[1;32m     68\u001b[0m sqrt_one_minus_alpha_s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha[s])\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Estimate the original image using the decoder\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m x_0_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Calculate the estimated noise using Eq. (3)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m z_hat \u001b[38;5;241m=\u001b[39m (x_s \u001b[38;5;241m-\u001b[39m sqrt_alpha_s \u001b[38;5;241m*\u001b[39m x_0_hat) \u001b[38;5;241m/\u001b[39m sqrt_one_minus_alpha_s\n",
      "File \u001b[0;32m~/miniconda3/envs/parthaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/parthaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, t):\n\u001b[0;32m---> 27\u001b[0m     timestep_emb \u001b[38;5;241m=\u001b[39m \u001b[43mget_timestep_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestep_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     timestep_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimestep_mlp(timestep_emb)\n\u001b[1;32m     30\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m, in \u001b[0;36mget_timestep_embedding\u001b[0;34m(timesteps, embedding_dim)\u001b[0m\n\u001b[1;32m     14\u001b[0m emb \u001b[38;5;241m=\u001b[39m emb\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mtimesteps\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     15\u001b[0m emb \u001b[38;5;241m=\u001b[39m timesteps\u001b[38;5;241m.\u001b[39mfloat()[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m emb[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[0;32m---> 16\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embedding_dim \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# zero pad\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(emb, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the input shape, latent dimensions, and output shape\n",
    "input_shape = (1, 32, 32)  # Shape for grayscale CIFAR-10 (1 channel, 32x32 images)\n",
    "latent_dims = [32, 64, 128, 256, 512]  # Updated latent dimensions\n",
    "output_shape = (1, 32, 32)  # Shape for grayscale CIFAR-10\n",
    "\n",
    "# Create an instance of the EchoModel\n",
    "model = EchoModel(input_shape, latent_dims, output_shape).to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define the number of epochs and loss weights\n",
    "num_epochs = 100\n",
    "loss_weights = {'reconstruction': 1.0, 'mi_penalty': 0.0}  # Adjust the weights as needed\n",
    "\n",
    "# Train the model\n",
    "trained_model = train(model, optimizer, train_loader, device, num_epochs, loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qmfrva2uRuvu",
   "metadata": {
    "id": "qmfrva2uRuvu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
