{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc0c0f7-7683-4710-b06a-b4f1e4abd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary PyTorch libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Additional libraries for visualization and utilities\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from unet import UNet\n",
    "from unet_decoder import UNetDecoder\n",
    "from echo import echo_sample, echo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbb9823-564c-4735-a473-ad93c564ba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    \"\"\"Selects the best available device for PyTorch computations.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The selected device.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e76e694-9980-4207-aff0-adc89538f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in the dataset: 60000\n",
      "Number of images in the training set: 48000\n",
      "Number of images in the validation set: 12000\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor,Resize\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5,), (0.5,))  # Normalize with MNIST mean and std\n",
    "])\n",
    "\n",
    "\n",
    "# Load the CelebA dataset\n",
    "dataset = datasets.MNIST(root='./data', download=True, transform=transform)\n",
    "\n",
    "# Print the total number of images in the dataset\n",
    "print(f\"Total number of images in the dataset: {len(dataset)}\")\n",
    "\n",
    "# Splitting dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Print the number of images in the train and validation sets\n",
    "print(f\"Number of images in the training set: {len(train_dataset)}\")\n",
    "print(f\"Number of images in the validation set: {len(val_dataset)}\")\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87700d40-8a84-4c37-ad3c-30da357df203",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dims):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_dims = latent_dims\n",
    "\n",
    "        self.unet = UNet(\n",
    "            n_channels=input_shape[0],\n",
    "            n_classes=input_shape[0],  # Ensure the output channels match the input channels\n",
    "            bilinear=True\n",
    "        )\n",
    "\n",
    "        # Output layers for mean and log variance\n",
    "        self.out_mean = nn.Conv2d(input_shape[0], input_shape[0], kernel_size=1)\n",
    "        self.out_log_var = nn.Conv2d(input_shape[0], input_shape[0], kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.unet(x)\n",
    "        f_x = torch.tanh(self.out_mean(x))\n",
    "        log_var = torch.sigmoid(self.out_log_var(x))\n",
    "        return f_x, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a008de-3e56-4ab4-a4b9-709ed3160b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColdDiffusionModel(nn.Module):\n",
    "    def __init__(self, encoder, input_shape, T=1000):\n",
    "        super(ColdDiffusionModel, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.T = T\n",
    "        self.encoder = encoder\n",
    "        self.decoder = UNetDecoder(n_channels=input_shape[0])\n",
    "\n",
    "        # Define the noise schedule\n",
    "        self.alpha = self.create_noise_schedule(T)\n",
    "\n",
    "    def create_noise_schedule(self, T):\n",
    "        beta_start = 0.0001\n",
    "        beta_end = 0.02\n",
    "        betas = torch.linspace(beta_start, beta_end, T)\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        return alphas_cumprod\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Calculate the gaussian noise tensor\n",
    "        batch_size = x.shape[0]\n",
    "        f_x, sx_matrix = self.encoder(x)\n",
    "        epsilon = echo_sample((f_x, sx_matrix)).detach()\n",
    "        z = f_x + sx_matrix * epsilon\n",
    "        \n",
    "        del epsilon \n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #sample a timestep t\n",
    "        t = np.random.randint(0, self.T)\n",
    "        # Retrieve noise scheduler alpha_T\n",
    "        alpha_t = self.alpha[t]\n",
    "\n",
    "        # Calculate square root alphas\n",
    "        sqrt_alpha_t = torch.sqrt(alpha_t)\n",
    "        sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)\n",
    "        \n",
    "        # Perform the weighted sum\n",
    "        x_t = sqrt_alpha_t * x + sqrt_one_minus_alpha_t * z\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #Calculate the timestep tensor\n",
    "        t = torch.tensor([t] * x_t.size(0), dtype=torch.long).to(x_t.device)\n",
    "\n",
    "        # Perform the reconstruction process \n",
    "        estimated_image = self.decoder(x_t,t)\n",
    "        torch.cuda.empty_cache()\n",
    "        return estimated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983ad71a-c21f-4dad-95cc-19f89eab7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_module(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_module(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b278bd6b-4148-49bd-bf03-1c7b2609abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, filename=\"checkpoint.pth\"):\n",
    "    \"\"\"Saves the model and optimizer state at the specified path.\"\"\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, filename)\n",
    "    print(f\"Checkpoint saved at epoch {epoch} to {filename}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename=\"checkpoint.pth\"):\n",
    "    \"\"\"Loads the model and optimizer state from the specified path.\"\"\"\n",
    "    if os.path.isfile(filename):\n",
    "        checkpoint = torch.load(filename)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        print(f\"Checkpoint loaded from {filename}, resuming training from epoch {epoch}\")\n",
    "        return epoch\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {filename}, starting from scratch.\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25cf69d8-ecb6-4c29-878d-3c2589834d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Importing time to log the duration\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient computation during validation\n",
    "        for data, _ in val_loader:\n",
    "            data = data.to(device)\n",
    "            # fx, sx_matrix = model(data)\n",
    "            # mi_loss = echo_loss(sx_matrix)\n",
    "            # total_val_loss += mi_loss\n",
    "            estimated_image = model(data)\n",
    "            reconstruction_loss = nn.functional.l1_loss(data, estimated_image)\n",
    "            total_val_loss += reconstruction_loss.item()  # Accumulate the validation loss\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)  # Calculate average loss\n",
    "    return avg_val_loss\n",
    "\n",
    "def train(model, optimizer, train_loader, device,start_epoch, num_epochs, filename):\n",
    "    model.train()\n",
    "    # freeze_module(model.encoder)\n",
    "\n",
    "    for epoch in range(start_epoch+1, num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_start_time = time.time()  # Time tracking for the epoch\n",
    "\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch_idx, (data, _) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)):\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            estimated_image = model(data)\n",
    "            # total_loss = echo_loss(sx_matrix)\n",
    "            total_loss = torch.nn.functional.l1_loss(data, estimated_image)\n",
    "\n",
    "            # Backward pass\n",
    "            if not torch.isnan(total_loss).any():\n",
    "                total_loss.backward()\n",
    "            else:\n",
    "                pass\n",
    "                print(f\"Warning: NaN detected in total_loss at batch {batch_idx+1}, skipping backward pass.\")\n",
    "\n",
    "            optimizer.step()  # Only step the optimizer every `accumulation_steps`\n",
    "            optimizer.zero_grad()  # Reset gradients only after accumulation\n",
    "\n",
    "            # Safe-guarding against NaN for epoch_loss\n",
    "            if not torch.isnan(total_loss).any():\n",
    "                epoch_loss += total_loss.item()\n",
    "            else:\n",
    "                epoch_loss += 0.0\n",
    "                print(f\"NaN detected, not adding to epoch_loss at batch {batch_idx+1}\")\n",
    "\n",
    "        # Save the model checkpoint\n",
    "        save_checkpoint(epoch, model, optimizer, filename)\n",
    "        \n",
    "        # Average loss after training for an epoch\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {time.time() - epoch_start_time:.2f} seconds, Avg Loss: {avg_loss}\")\n",
    "\n",
    "        # Validation phase\n",
    "        avg_val_loss = validate(model, val_loader, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] validation completed, Avg Validation Loss: {avg_val_loss}\")\n",
    "        \n",
    "    # unfreeze_module(model.encoder)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc54c1c-d710-406e-95a6-ecc205bbf18d",
   "metadata": {},
   "source": [
    "## Train model to minimize mi loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a8e54a-c7f5-40f2-9293-0b4e7785ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found at celeba_encoder.pth, starting from scratch.\n",
      "The training ended in epoch number: -1\n",
      "Starting epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 0 to celeba_encoder.pth\n",
      "Epoch [1/50] completed in 7193.37 seconds, Avg Loss: 30.05862258881155\n",
      "Epoch [1/50] validation completed, Avg Validation Loss: -43.540096282958984\n",
      "Starting epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 1 to celeba_encoder.pth\n",
      "Epoch [2/50] completed in 7825.98 seconds, Avg Loss: -34.57861584436683\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe training ended in epoch number: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, device, start_epoch, num_epochs, filename)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mepoch_start_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds, Avg Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     avg_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] validation completed, Avg Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# unfreeze_module(model.encoder)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, val_loader, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m fx, sx_matrix \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m---> 12\u001b[0m mi_loss \u001b[38;5;241m=\u001b[39m \u001b[43mecho_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43msx_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m total_val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mi_loss\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# estimated_image = model(data)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# reconstruction_loss = nn.functional.l1_loss(data, estimated_image)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# total_val_loss += reconstruction_loss.item()  # Accumulate the validation loss\u001b[39;00m\n",
      "File \u001b[0;32m~/echo_diffusion/echo.py:67\u001b[0m, in \u001b[0;36mecho_loss\u001b[0;34m(S)\u001b[0m\n\u001b[1;32m     64\u001b[0m scaled_S \u001b[38;5;241m=\u001b[39m scaling_factor \u001b[38;5;241m*\u001b[39m S\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Perform Singular Value Decomposition\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m U, S_values, V \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_S\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Calculate the log determinant using the singular values\u001b[39;00m\n\u001b[1;32m     70\u001b[0m log_singular_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(S_values \u001b[38;5;241m+\u001b[39m epsilon)  \u001b[38;5;66;03m# Add epsilon to avoid log(0)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the input shape\n",
    "input_shape = (1, 28, 28)\n",
    "latent_dims = latent_dims = [64, 128, 256, 512]\n",
    "\n",
    "# Create an instance of encoder model\n",
    "encoder = Encoder(input_shape,latent_dims).to(device)\n",
    "\n",
    "# Create the Diffuion Model\n",
    "model = ColdDiffusionModel(encoder, input_shape).to(device)\n",
    "\n",
    "# Define the optimizer \n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "# Define the number of epochs and loss weights\n",
    "num_epochs = 50\n",
    "\n",
    "# Filename\n",
    "filename = \"echo_cold_l1.pth\"\n",
    "\n",
    "# Load the model training checkpoint\n",
    "start_epoch = load_checkpoint(model, optimizer, filename)\n",
    "\n",
    "print(f\"The training ended in epoch number: {start_epoch}\")\n",
    "\n",
    "# Train the model\n",
    "trained_model = train(encoder, optimizer, train_loader, device, start_epoch, num_epochs, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434f7a1a-1b2a-4b04-b9c6-e438bc4dae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found at echo_cold_l1.pth, starting from scratch.\n",
      "Starting epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|                                       | 0/375 [00:00<?, ?it/s]/root/miniconda3/envs/parthaenv/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 0 to echo_cold_l1.pth\n",
      "Epoch [1/50] completed in 262.33 seconds, Avg Loss: 0.1423209744989872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/parthaenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] validation completed, Avg Validation Loss: 0.26100477837818736\n",
      "Starting epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 1 to echo_cold_l1.pth\n",
      "Epoch [2/50] completed in 252.09 seconds, Avg Loss: 0.12255473067363103\n",
      "Epoch [2/50] validation completed, Avg Validation Loss: 0.09031156505993072\n",
      "Starting epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 2 to echo_cold_l1.pth\n",
      "Epoch [3/50] completed in 259.03 seconds, Avg Loss: 0.07561605255802473\n",
      "Epoch [3/50] validation completed, Avg Validation Loss: 0.08798585130654751\n",
      "Starting epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 3 to echo_cold_l1.pth\n",
      "Epoch [4/50] completed in 242.15 seconds, Avg Loss: 0.06640429737170538\n",
      "Epoch [4/50] validation completed, Avg Validation Loss: 0.06790604434431867\n",
      "Starting epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 4 to echo_cold_l1.pth\n",
      "Epoch [5/50] completed in 252.11 seconds, Avg Loss: 0.0558649877011776\n",
      "Epoch [5/50] validation completed, Avg Validation Loss: 0.051226427322848045\n",
      "Starting epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 5 to echo_cold_l1.pth\n",
      "Epoch [6/50] completed in 255.23 seconds, Avg Loss: 0.053284491101900734\n",
      "Epoch [6/50] validation completed, Avg Validation Loss: 0.04647251632698673\n",
      "Starting epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 6 to echo_cold_l1.pth\n",
      "Epoch [7/50] completed in 268.77 seconds, Avg Loss: 0.05211373343070348\n",
      "Epoch [7/50] validation completed, Avg Validation Loss: 0.05890364310842879\n",
      "Starting epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 7 to echo_cold_l1.pth\n",
      "Epoch [8/50] completed in 271.73 seconds, Avg Loss: 0.04769241132835547\n",
      "Epoch [8/50] validation completed, Avg Validation Loss: 0.04800962730053258\n",
      "Starting epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 8 to echo_cold_l1.pth\n",
      "Epoch [9/50] completed in 264.22 seconds, Avg Loss: 0.0443121669391791\n",
      "Epoch [9/50] validation completed, Avg Validation Loss: 0.04785057387136398\n",
      "Starting epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 9 to echo_cold_l1.pth\n",
      "Epoch [10/50] completed in 266.65 seconds, Avg Loss: 0.044074936255812644\n",
      "Epoch [10/50] validation completed, Avg Validation Loss: 0.037986457407315995\n",
      "Starting epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 10 to echo_cold_l1.pth\n",
      "Epoch [11/50] completed in 277.84 seconds, Avg Loss: 0.04481898020456235\n",
      "Epoch [11/50] validation completed, Avg Validation Loss: 0.05340692563418378\n",
      "Starting epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 11 to echo_cold_l1.pth\n",
      "Epoch [12/50] completed in 272.98 seconds, Avg Loss: 0.04437011337776979\n",
      "Epoch [12/50] validation completed, Avg Validation Loss: 0.04330075028887455\n",
      "Starting epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 12 to echo_cold_l1.pth\n",
      "Epoch [13/50] completed in 277.92 seconds, Avg Loss: 0.03967276374995708\n",
      "Epoch [13/50] validation completed, Avg Validation Loss: 0.03654137890825563\n",
      "Starting epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 13 to echo_cold_l1.pth\n",
      "Epoch [14/50] completed in 266.02 seconds, Avg Loss: 0.03800988150884708\n",
      "Epoch [14/50] validation completed, Avg Validation Loss: 0.03422987994123647\n",
      "Starting epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 14 to echo_cold_l1.pth\n",
      "Epoch [15/50] completed in 267.05 seconds, Avg Loss: 0.03869976848612229\n",
      "Epoch [15/50] validation completed, Avg Validation Loss: 0.03358445697008295\n",
      "Starting epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 15 to echo_cold_l1.pth\n",
      "Epoch [16/50] completed in 273.66 seconds, Avg Loss: 0.03537443456550439\n",
      "Epoch [16/50] validation completed, Avg Validation Loss: 0.03816520026389589\n",
      "Starting epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 16 to echo_cold_l1.pth\n",
      "Epoch [17/50] completed in 271.79 seconds, Avg Loss: 0.035559282682836056\n",
      "Epoch [17/50] validation completed, Avg Validation Loss: 0.03487600122598258\n",
      "Starting epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 17 to echo_cold_l1.pth\n",
      "Epoch [18/50] completed in 273.53 seconds, Avg Loss: 0.035846908042828245\n",
      "Epoch [18/50] validation completed, Avg Validation Loss: 0.033372081221735225\n",
      "Starting epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 18 to echo_cold_l1.pth\n",
      "Epoch [19/50] completed in 265.61 seconds, Avg Loss: 0.03469447027891874\n",
      "Epoch [19/50] validation completed, Avg Validation Loss: 0.029990396690257687\n",
      "Starting epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 19 to echo_cold_l1.pth\n",
      "Epoch [20/50] completed in 269.38 seconds, Avg Loss: 0.03464005715151628\n",
      "Epoch [20/50] validation completed, Avg Validation Loss: 0.03408877414829554\n",
      "Starting epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 20 to echo_cold_l1.pth\n",
      "Epoch [21/50] completed in 270.29 seconds, Avg Loss: 0.03282722634573777\n",
      "Epoch [21/50] validation completed, Avg Validation Loss: 0.03488705975023356\n",
      "Starting epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 21 to echo_cold_l1.pth\n",
      "Epoch [22/50] completed in 268.70 seconds, Avg Loss: 0.03309197571625312\n",
      "Epoch [22/50] validation completed, Avg Validation Loss: 0.032640219458002356\n",
      "Starting epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 22 to echo_cold_l1.pth\n",
      "Epoch [23/50] completed in 266.00 seconds, Avg Loss: 0.03124111179759105\n",
      "Epoch [23/50] validation completed, Avg Validation Loss: 0.03355090865033104\n",
      "Starting epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 23 to echo_cold_l1.pth\n",
      "Epoch [24/50] completed in 271.85 seconds, Avg Loss: 0.03114078328261773\n",
      "Epoch [24/50] validation completed, Avg Validation Loss: 0.03124344759085711\n",
      "Starting epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 24 to echo_cold_l1.pth\n",
      "Epoch [25/50] completed in 267.52 seconds, Avg Loss: 0.028998325449724992\n",
      "Epoch [25/50] validation completed, Avg Validation Loss: 0.03461896770812096\n",
      "Starting epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 25 to echo_cold_l1.pth\n",
      "Epoch [26/50] completed in 266.89 seconds, Avg Loss: 0.030247027916212876\n",
      "Epoch [26/50] validation completed, Avg Validation Loss: 0.02860465049347345\n",
      "Starting epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 26 to echo_cold_l1.pth\n",
      "Epoch [27/50] completed in 275.13 seconds, Avg Loss: 0.031160287780066333\n",
      "Epoch [27/50] validation completed, Avg Validation Loss: 0.02871551387447943\n",
      "Starting epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 27 to echo_cold_l1.pth\n",
      "Epoch [28/50] completed in 260.65 seconds, Avg Loss: 0.029389260597527028\n",
      "Epoch [28/50] validation completed, Avg Validation Loss: 0.029308358682913982\n",
      "Starting epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 28 to echo_cold_l1.pth\n",
      "Epoch [29/50] completed in 275.76 seconds, Avg Loss: 0.03093373406926791\n",
      "Epoch [29/50] validation completed, Avg Validation Loss: 0.027023046386447994\n",
      "Starting epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 29 to echo_cold_l1.pth\n",
      "Epoch [30/50] completed in 275.18 seconds, Avg Loss: 0.02678582313656807\n",
      "Epoch [30/50] validation completed, Avg Validation Loss: 0.03084039442399715\n",
      "Starting epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 30 to echo_cold_l1.pth\n",
      "Epoch [31/50] completed in 273.88 seconds, Avg Loss: 0.027217116783062618\n",
      "Epoch [31/50] validation completed, Avg Validation Loss: 0.026267779020077372\n",
      "Starting epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 31 to echo_cold_l1.pth\n",
      "Epoch [32/50] completed in 274.16 seconds, Avg Loss: 0.02893913215895494\n",
      "Epoch [32/50] validation completed, Avg Validation Loss: 0.03498779532519427\n",
      "Starting epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 32 to echo_cold_l1.pth\n",
      "Epoch [33/50] completed in 268.55 seconds, Avg Loss: 0.02834886105110248\n",
      "Epoch [33/50] validation completed, Avg Validation Loss: 0.025317009597858216\n",
      "Starting epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 33 to echo_cold_l1.pth\n",
      "Epoch [34/50] completed in 273.93 seconds, Avg Loss: 0.02660774794469277\n",
      "Epoch [34/50] validation completed, Avg Validation Loss: 0.0261287635509321\n",
      "Starting epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 34 to echo_cold_l1.pth\n",
      "Epoch [35/50] completed in 272.80 seconds, Avg Loss: 0.025372469084958237\n",
      "Epoch [35/50] validation completed, Avg Validation Loss: 0.02783017503493961\n",
      "Starting epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 35 to echo_cold_l1.pth\n",
      "Epoch [36/50] completed in 267.34 seconds, Avg Loss: 0.026274789425234\n",
      "Epoch [36/50] validation completed, Avg Validation Loss: 0.02709587814008936\n",
      "Starting epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 36 to echo_cold_l1.pth\n",
      "Epoch [37/50] completed in 276.04 seconds, Avg Loss: 0.02602455440411965\n",
      "Epoch [37/50] validation completed, Avg Validation Loss: 0.026130817721578034\n",
      "Starting epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 37 to echo_cold_l1.pth\n",
      "Epoch [38/50] completed in 258.14 seconds, Avg Loss: 0.025797217878202598\n",
      "Epoch [38/50] validation completed, Avg Validation Loss: 0.026282746998712102\n",
      "Starting epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 38 to echo_cold_l1.pth\n",
      "Epoch [39/50] completed in 276.52 seconds, Avg Loss: 0.024548527253170808\n",
      "Epoch [39/50] validation completed, Avg Validation Loss: 0.02539497643629921\n",
      "Starting epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 39 to echo_cold_l1.pth\n",
      "Epoch [40/50] completed in 272.71 seconds, Avg Loss: 0.025944218158721923\n",
      "Epoch [40/50] validation completed, Avg Validation Loss: 0.024007169886472376\n",
      "Starting epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 40 to echo_cold_l1.pth\n",
      "Epoch [41/50] completed in 273.40 seconds, Avg Loss: 0.024750207670032977\n",
      "Epoch [41/50] validation completed, Avg Validation Loss: 0.026546762473484937\n",
      "Starting epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 41 to echo_cold_l1.pth\n",
      "Epoch [42/50] completed in 271.27 seconds, Avg Loss: 0.024893804964919886\n",
      "Epoch [42/50] validation completed, Avg Validation Loss: 0.02631436490473595\n",
      "Starting epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 42 to echo_cold_l1.pth\n",
      "Epoch [43/50] completed in 275.86 seconds, Avg Loss: 0.02523096850514412\n",
      "Epoch [43/50] validation completed, Avg Validation Loss: 0.027897465944369423\n",
      "Starting epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 43 to echo_cold_l1.pth\n",
      "Epoch [44/50] completed in 268.67 seconds, Avg Loss: 0.023480329183240733\n",
      "Epoch [44/50] validation completed, Avg Validation Loss: 0.022843897738989365\n",
      "Starting epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 44 to echo_cold_l1.pth\n",
      "Epoch [45/50] completed in 270.47 seconds, Avg Loss: 0.024555062390863896\n",
      "Epoch [45/50] validation completed, Avg Validation Loss: 0.02833291779252443\n",
      "Starting epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 45 to echo_cold_l1.pth\n",
      "Epoch [46/50] completed in 274.59 seconds, Avg Loss: 0.02357568446795146\n",
      "Epoch [46/50] validation completed, Avg Validation Loss: 0.01994654778985584\n",
      "Starting epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 46 to echo_cold_l1.pth\n",
      "Epoch [47/50] completed in 267.34 seconds, Avg Loss: 0.02341543814291557\n",
      "Epoch [47/50] validation completed, Avg Validation Loss: 0.023550225580309298\n",
      "Starting epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 47 to echo_cold_l1.pth\n",
      "Epoch [48/50] completed in 274.55 seconds, Avg Loss: 0.02594897596538067\n",
      "Epoch [48/50] validation completed, Avg Validation Loss: 0.025902247115811135\n",
      "Starting epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 48 to echo_cold_l1.pth\n",
      "Epoch [49/50] completed in 273.14 seconds, Avg Loss: 0.023114223991831145\n",
      "Epoch [49/50] validation completed, Avg Validation Loss: 0.021873231531378438\n",
      "Starting epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 49 to echo_cold_l1.pth\n",
      "Epoch [50/50] completed in 260.18 seconds, Avg Loss: 0.02276922165354093\n",
      "Epoch [50/50] validation completed, Avg Validation Loss: 0.03026146978694708\n"
     ]
    }
   ],
   "source": [
    "# Create the Diffuion Model\n",
    "model = ColdDiffusionModel(encoder, input_shape).to(device)\n",
    "\n",
    "# Define the optimizer \n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "# Filename \n",
    "filename = \"echo_cold_l1.pth\"\n",
    "\n",
    "start_epoch = load_checkpoint(model, optimizer, filename)\n",
    "\n",
    "# Train the model\n",
    "trained_model = train(model, optimizer, train_loader, device, start_epoch, num_epochs, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df8281e2-8bbd-4fbc-9ea9-329781794ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from echo_cold_l1.pth, resuming training from epoch 49\n",
      "The training ended in epoch number: 49\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape\n",
    "input_shape = (1, 28, 28)\n",
    "\n",
    "# Example usage\n",
    "model = ColdDiffusionModel(encoder, input_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "start_epoch = load_checkpoint(model, optimizer, filename)\n",
    "print(f\"The training ended in epoch number: {start_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177fea68-4883-4633-a668-868b07bd038e",
   "metadata": {},
   "source": [
    "## Sampling according to Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "696b8b8c-72d5-41d2-bdbb-81cfcf652d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the necessary parameters and variables\n",
    "T = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "beta = torch.linspace(beta_start, beta_end, T)\n",
    "alpha = 1 - beta\n",
    "alpha = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "batch_size = 128\n",
    "model.eval()\n",
    "\n",
    "sampled_data = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(val_loader, desc=\"Sampling Progress:\", leave=False)):\n",
    "        data = data.to(device)\n",
    "        f_x, sx_matrix = model.encoder(data)\n",
    "        epsilon = echo_sample((f_x, sx_matrix))\n",
    "        x = f_x + sx_matrix * epsilon\n",
    "        for s in range(T-1, 0, -1):\n",
    "            t = torch.tensor([s] * data.size(0), dtype=torch.long).to(device)\n",
    "            x_hat = model.decoder(x, t)\n",
    "            z_hat = (1.0 / torch.sqrt(1-alpha[s])) * (x - torch.sqrt(alpha[s]) * x_hat)\n",
    "            x = torch.sqrt(alpha[s-1]) * x_hat + torch.sqrt(1 - alpha[s-1]) * z_hat\n",
    "        \n",
    "        # Reverse normalization\n",
    "        x = x * 0.3081 + 0.1307\n",
    "        x = (x.clamp(0, 1) * 255).type(torch.uint8)\n",
    "        \n",
    "        # Store the original and sampled images\n",
    "        for i in range(x.size(0)):\n",
    "            sampled_data[batch_idx * batch_size + i] = {\n",
    "                'original_image': (data[i].cpu() * 0.3081 + 0.1307).clamp(0, 1),  # Reverse normalization for original image\n",
    "                'sampled': x[i].cpu()\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0df8f6ba-0c1e-4aad-8470-2710fb1e006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data saved to mnist_echo_cold_alg1.pt\n"
     ]
    }
   ],
   "source": [
    "filename = 'mnist_echo_cold_alg1.pt'\n",
    "# Save the dictionary to a .pt file\n",
    "torch.save(sampled_data, filename)\n",
    "\n",
    "print(f\"Sampled data saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "826d3db5-c357-4b0c-9729-d0ec57f57f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(sampled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e396ae46-c395-450b-ae29-b2c87d58c3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved data\n",
    "sampled_data = torch.load(filename)\n",
    "\n",
    "# Access a specific entry\n",
    "index = 120 # Replace with the index you want to check\n",
    "original_image = sampled_data[index]['original_image']\n",
    "sampled_image = sampled_data[index]['sampled']\n",
    "\n",
    "\n",
    "\n",
    "# Convert the tensor to a numpy array\n",
    "original_image = original_image.cpu().numpy().transpose(1, 2, 0)\n",
    "sampled_image = sampled_image.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Plot the images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(original_image, cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(sampled_image, cmap='gray')\n",
    "ax[1].set_title('Sampled Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f71fb4-7e01-43de-af28-210ef089e45b",
   "metadata": {},
   "source": [
    "## Sampling according to Algorithm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5983df70-9316-49f4-9148-07b56e36aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the necessary parameters and variables\n",
    "T = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "beta = torch.linspace(beta_start, beta_end, T)\n",
    "alpha = 1 - beta\n",
    "alpha = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "batch_size = 128\n",
    "model.eval()\n",
    "\n",
    "sampled_data = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(val_loader, desc=\"Sampling Progress:\", leave=False)):  # Corrected line\n",
    "        data = data.to(device)\n",
    "        f_x, sx_matrix = model.encoder(data)\n",
    "        epsilon = echo_sample((f_x, sx_matrix))\n",
    "        x = f_x + sx_matrix * epsilon\n",
    "        for s in range(T-1, -1, -1):\n",
    "            t = torch.tensor([s] * data.size(0), dtype=torch.long).to(device)\n",
    "            x_hat = model.decoder(x, t)\n",
    "            z_hat = (1.0 / torch.sqrt(1-alpha[s])) * (x - torch.sqrt(alpha[s]) * x_hat)\n",
    "            D_s = torch.sqrt(alpha[s]) * x_hat + torch.sqrt(1-alpha[s]) * z_hat\n",
    "            D_s_minus_one = torch.sqrt(alpha[s-1]) * x_hat + torch.sqrt(1-alpha[s-1]) * z_hat\n",
    "            x = x - D_s + D_s_minus_one\n",
    "        \n",
    "        # Reverse normalization\n",
    "        x = x * 0.3081 + 0.1307\n",
    "        x = (x.clamp(0, 1) * 255).type(torch.uint8)\n",
    "        \n",
    "        # Store the original and sampled images\n",
    "        for i in range(x.size(0)):\n",
    "            sampled_data[batch_idx * batch_size + i] = {\n",
    "                'original_image': data[i].cpu() * 0.3081 + 0.1307,  # Reverse normalization for original image\n",
    "                'sampled': x[i].cpu()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "162266e3-023c-4aaf-9bdd-ddea1045bb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data saved to mnist_echo_cold_alg2.pt\n"
     ]
    }
   ],
   "source": [
    "filename = 'mnist_echo_cold_alg2.pt'\n",
    "# Save the dictionary to a .pt file\n",
    "torch.save(sampled_data, filename)\n",
    "\n",
    "print(f\"Sampled data saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff44148e-6d92-47f8-b425-7440371c5f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(sampled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e72ce7b-4aa8-4202-9dde-e6797d773dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved data\n",
    "sampled_data = torch.load(filename)\n",
    "\n",
    "# Access a specific entry\n",
    "index = 120 # Replace with the index you want to check\n",
    "original_image = sampled_data[index]['original_image']\n",
    "sampled_image = sampled_data[index]['sampled']\n",
    "\n",
    "\n",
    "\n",
    "# Convert the tensor to a numpy array\n",
    "original_image = original_image.cpu().numpy().transpose(1, 2, 0)\n",
    "sampled_image = sampled_image.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Plot the images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(original_image, cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(sampled_image, cmap='gray')\n",
    "ax[1].set_title('Sampled Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228bfa3b-6c80-4d46-a8d5-6d62e7321730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
