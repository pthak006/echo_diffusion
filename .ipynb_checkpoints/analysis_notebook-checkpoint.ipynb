{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e89c3f2-430c-4990-8fe3-5085e3444190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary PyTorch libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Additional libraries for visualization and utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unet_decoder import UNetDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9430df8a-5d8e-41fd-8c15-4fd453a89e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    \"\"\"Selects the best available device for PyTorch computations.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The selected device.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f776dc-889a-4dbe-9d1c-eeec1694b466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in the dataset: 60000\n",
      "Number of images in the training set: 48000\n",
      "Number of images in the validation set: 12000\n",
      "Number of batches in the training loader: 375\n",
      "Total number of images in the training loader: 48000\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor,Resize\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define the transformation with resizing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load the Omniglot dataset\n",
    "dataset = datasets.MNIST(root='./data', download=True, transform=transform)\n",
    "\n",
    "# Print the total number of images in the dataset\n",
    "print(f\"Total number of images in the dataset: {len(dataset)}\")\n",
    "\n",
    "# Splitting dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Print the number of images in the train and validation sets\n",
    "print(f\"Number of images in the training set: {len(train_dataset)}\")\n",
    "print(f\"Number of images in the validation set: {len(val_dataset)}\")\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Inspect the contents of the train_loader\n",
    "train_batches = 0\n",
    "for batch in train_loader:\n",
    "    train_batches += 1\n",
    "\n",
    "print(f\"Number of batches in the training loader: {train_batches}\")\n",
    "print(f\"Total number of images in the training loader: {train_batches * 128}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022279c2-884d-4dbf-896c-3580e14dd6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and normalized 4096 sampled images from mnist_gaussian_ddpm.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the sampled data\n",
    "sampled_data_path = 'mnist_gaussian_ddpm.pt'\n",
    "sampled_data = torch.load(sampled_data_path)\n",
    "\n",
    "# Extract the images from the dictionary\n",
    "sampled_images = [sampled_data[key]['sampled'] for key in sampled_data]\n",
    "sampled_images = torch.stack(sampled_images)  # Convert list to tensor\n",
    "\n",
    "# Normalize the sampled images\n",
    "sampled_images = sampled_images.float() / 255.0  # Scale back to [0, 1]\n",
    "sampled_images = (sampled_images - 0.1307) / 0.3081  # Normalize using the same mean and std as MNIST\n",
    "\n",
    "print(f\"Loaded and normalized {sampled_images.size(0)} sampled images from {sampled_data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926d07a-b0c0-4937-9825-a645a82c659e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
