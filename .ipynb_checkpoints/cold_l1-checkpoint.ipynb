{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc0c0f7-7683-4710-b06a-b4f1e4abd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary PyTorch libraries\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Additional libraries for visualization and utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unet_decoder import UNetDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbb9823-564c-4735-a473-ad93c564ba7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    \"\"\"Selects the best available device for PyTorch computations.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The selected device.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e76e694-9980-4207-aff0-adc89538f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Total number of images in the dataset: 19280\n",
      "Number of images in the training set: 15424\n",
      "Number of images in the validation set: 3856\n",
      "Number of batches in the training loader: 121\n",
      "Total number of images in the training loader: 15488\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor,Resize\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define the transformation with resizing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # Resize to 28x28\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Load the Omniglot dataset\n",
    "dataset = datasets.Omniglot(root='./data', download=True, transform=transform, background=True)\n",
    "\n",
    "# Print the total number of images in the dataset\n",
    "print(f\"Total number of images in the dataset: {len(dataset)}\")\n",
    "\n",
    "# Splitting dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Print the number of images in the train and validation sets\n",
    "print(f\"Number of images in the training set: {len(train_dataset)}\")\n",
    "print(f\"Number of images in the validation set: {len(val_dataset)}\")\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Inspect the contents of the train_loader\n",
    "train_batches = 0\n",
    "for batch in train_loader:\n",
    "    train_batches += 1\n",
    "\n",
    "print(f\"Number of batches in the training loader: {train_batches}\")\n",
    "print(f\"Total number of images in the training loader: {train_batches * 128}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a008de-3e56-4ab4-a4b9-709ed3160b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColdDiffusionModel(nn.Module):\n",
    "    def __init__(self, input_shape, T=1000):\n",
    "        super(ColdDiffusionModel, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.T = T\n",
    "        self.decoder = UNetDecoder(n_channels=input_shape[0])\n",
    "\n",
    "        # Define the noise schedule\n",
    "        self.alpha = self.create_noise_schedule(T)\n",
    "\n",
    "    def create_noise_schedule(self, T):\n",
    "        beta_start = 0.0001\n",
    "        beta_end = 0.02\n",
    "        betas = torch.linspace(beta_start, beta_end, T)\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        return alphas_cumprod\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Calculate the gaussian noise tensor\n",
    "        batch_size = x.shape[0]\n",
    "        epsilon = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #sample a timestep t\n",
    "        t = np.random.randint(0, self.T)\n",
    "        # Retrieve noise scheduler alpha_T\n",
    "        alpha_t = self.alpha[t]\n",
    "\n",
    "        # Calculate square root alphas\n",
    "        sqrt_alpha_t = torch.sqrt(alpha_t)\n",
    "        sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)\n",
    "        \n",
    "        # Perform the weighted sum\n",
    "        x_t = sqrt_alpha_t * x + sqrt_one_minus_alpha_t * epsilon\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #Calculate the timestep tensor\n",
    "        t = torch.tensor([t] * x_t.size(0), dtype=torch.long).to(x_t.device)\n",
    "\n",
    "        # Perform the reconstruction process using Algorithm 2\n",
    "        estimated_x = self.decoder(x_t,t)\n",
    "        torch.cuda.empty_cache()\n",
    "        return estimated_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b278bd6b-4148-49bd-bf03-1c7b2609abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, filename=\"checkpoint.pth\"):\n",
    "    \"\"\"Saves the model and optimizer state at the specified path.\"\"\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, filename)\n",
    "    print(f\"Checkpoint saved at epoch {epoch} to {filename}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename=\"checkpoint.pth\"):\n",
    "    \"\"\"Loads the model and optimizer state from the specified path.\"\"\"\n",
    "    if os.path.isfile(filename):\n",
    "        checkpoint = torch.load(filename)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        print(f\"Checkpoint loaded from {filename}, resuming training from epoch {epoch}\")\n",
    "        return epoch\n",
    "    else:\n",
    "        print(f\"No checkpoint found at {filename}, starting from scratch.\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25cf69d8-ecb6-4c29-878d-3c2589834d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Importing time to log the duration\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient computation during validation\n",
    "        for data, _ in val_loader:\n",
    "            data = data.to(device)\n",
    "            estimated_image = model(data)\n",
    "            reconstruction_loss = nn.functional.l1_loss(data, estimated_image)\n",
    "            total_val_loss += reconstruction_loss.item()  # Accumulate the validation loss\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)  # Calculate average loss\n",
    "    return avg_val_loss\n",
    "\n",
    "def train(model, optimizer, train_loader, device, start_epoch, num_epochs, filename):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(start_epoch+1, num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_start_time = time.time()  # Time tracking for the epoch\n",
    "\n",
    "        print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch_idx, (data, _) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)):\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            estimated_image = model(data)\n",
    "            total_loss = nn.functional.l1_loss(data, estimated_image)\n",
    "\n",
    "            # Backward pass\n",
    "            if not torch.isnan(total_loss).any():\n",
    "                total_loss.backward()\n",
    "            else:\n",
    "                print(f\"Warning: NaN detected in total_loss at batch {batch_idx+1}, skipping backward pass.\")\n",
    "\n",
    "            optimizer.step()  # Only step the optimizer every `accumulation_steps`\n",
    "            optimizer.zero_grad()  # Reset gradients only after accumulation\n",
    "\n",
    "            # Safe-guarding against NaN for epoch_loss\n",
    "            if not torch.isnan(total_loss).any():\n",
    "                epoch_loss += total_loss.item()\n",
    "            else:\n",
    "                print(f\"NaN detected, not adding to epoch_loss at batch {batch_idx+1}\")\n",
    "\n",
    "        # Save the model checkpoint\n",
    "        save_checkpoint(epoch, model, optimizer, filename)\n",
    "        \n",
    "        # Average loss after training for an epoch\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {time.time() - epoch_start_time:.2f} seconds, Avg Loss: {avg_loss}\")\n",
    "\n",
    "        # Validation phase\n",
    "        avg_val_loss = validate(model, val_loader, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] validation completed, Avg Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "67a8e54a-c7f5-40f2-9293-0b4e7785ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from omniglot_cold_l1.pth, resuming training from epoch 349\n",
      "The training ended in epoch number: 349\n",
      "Starting epoch 351/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 350 to omniglot_cold_l1.pth\n",
      "Epoch [351/400] completed in 22.36 seconds, Avg Loss: 0.1432987860719527\n",
      "Epoch [351/400] validation completed, Avg Validation Loss: 0.22421935681373842\n",
      "Starting epoch 352/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 351 to omniglot_cold_l1.pth\n",
      "Epoch [352/400] completed in 21.87 seconds, Avg Loss: 0.16114567466511215\n",
      "Epoch [352/400] validation completed, Avg Validation Loss: 0.15520435331329221\n",
      "Starting epoch 353/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 352 to omniglot_cold_l1.pth\n",
      "Epoch [353/400] completed in 21.88 seconds, Avg Loss: 0.15709366729436827\n",
      "Epoch [353/400] validation completed, Avg Validation Loss: 0.15453696683529886\n",
      "Starting epoch 354/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 353 to omniglot_cold_l1.pth\n",
      "Epoch [354/400] completed in 21.86 seconds, Avg Loss: 0.15650337663563815\n",
      "Epoch [354/400] validation completed, Avg Validation Loss: 0.15612703465646313\n",
      "Starting epoch 355/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 354 to omniglot_cold_l1.pth\n",
      "Epoch [355/400] completed in 21.89 seconds, Avg Loss: 0.139152250321936\n",
      "Epoch [355/400] validation completed, Avg Validation Loss: 0.13020788553741672\n",
      "Starting epoch 356/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 355 to omniglot_cold_l1.pth\n",
      "Epoch [356/400] completed in 21.88 seconds, Avg Loss: 0.12574164760260542\n",
      "Epoch [356/400] validation completed, Avg Validation Loss: 0.11286567355836591\n",
      "Starting epoch 357/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 356 to omniglot_cold_l1.pth\n",
      "Epoch [357/400] completed in 21.88 seconds, Avg Loss: 0.11819093391176097\n",
      "Epoch [357/400] validation completed, Avg Validation Loss: 0.12901165264268075\n",
      "Starting epoch 358/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 357 to omniglot_cold_l1.pth\n",
      "Epoch [358/400] completed in 21.87 seconds, Avg Loss: 0.119816860599705\n",
      "Epoch [358/400] validation completed, Avg Validation Loss: 0.11593013046489607\n",
      "Starting epoch 359/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 358 to omniglot_cold_l1.pth\n",
      "Epoch [359/400] completed in 21.87 seconds, Avg Loss: 0.11185345835675878\n",
      "Epoch [359/400] validation completed, Avg Validation Loss: 0.09848685190081596\n",
      "Starting epoch 360/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 359 to omniglot_cold_l1.pth\n",
      "Epoch [360/400] completed in 21.88 seconds, Avg Loss: 0.10684676873997963\n",
      "Epoch [360/400] validation completed, Avg Validation Loss: 0.11148199955782583\n",
      "Starting epoch 361/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 360 to omniglot_cold_l1.pth\n",
      "Epoch [361/400] completed in 21.86 seconds, Avg Loss: 0.10861665388369117\n",
      "Epoch [361/400] validation completed, Avg Validation Loss: 0.1145406057757716\n",
      "Starting epoch 362/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 361 to omniglot_cold_l1.pth\n",
      "Epoch [362/400] completed in 21.97 seconds, Avg Loss: 0.11184911606910307\n",
      "Epoch [362/400] validation completed, Avg Validation Loss: 0.11255805212403497\n",
      "Starting epoch 363/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 362 to omniglot_cold_l1.pth\n",
      "Epoch [363/400] completed in 21.88 seconds, Avg Loss: 0.10547761671429823\n",
      "Epoch [363/400] validation completed, Avg Validation Loss: 0.10852048945643249\n",
      "Starting epoch 364/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 363 to omniglot_cold_l1.pth\n",
      "Epoch [364/400] completed in 21.91 seconds, Avg Loss: 0.11621320259195468\n",
      "Epoch [364/400] validation completed, Avg Validation Loss: 0.1165538264979278\n",
      "Starting epoch 365/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 364 to omniglot_cold_l1.pth\n",
      "Epoch [365/400] completed in 21.93 seconds, Avg Loss: 0.10531999514830753\n",
      "Epoch [365/400] validation completed, Avg Validation Loss: 0.10625969200965858\n",
      "Starting epoch 366/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 365 to omniglot_cold_l1.pth\n",
      "Epoch [366/400] completed in 21.92 seconds, Avg Loss: 0.10809050862915999\n",
      "Epoch [366/400] validation completed, Avg Validation Loss: 0.10687094878765845\n",
      "Starting epoch 367/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 366 to omniglot_cold_l1.pth\n",
      "Epoch [367/400] completed in 21.93 seconds, Avg Loss: 0.11365287442314477\n",
      "Epoch [367/400] validation completed, Avg Validation Loss: 0.10308198041973575\n",
      "Starting epoch 368/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 367 to omniglot_cold_l1.pth\n",
      "Epoch [368/400] completed in 21.93 seconds, Avg Loss: 0.1028818119517412\n",
      "Epoch [368/400] validation completed, Avg Validation Loss: 0.1254186276346445\n",
      "Starting epoch 369/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 368 to omniglot_cold_l1.pth\n",
      "Epoch [369/400] completed in 21.86 seconds, Avg Loss: 0.11658262890140134\n",
      "Epoch [369/400] validation completed, Avg Validation Loss: 0.1226054314644106\n",
      "Starting epoch 370/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 369 to omniglot_cold_l1.pth\n",
      "Epoch [370/400] completed in 21.86 seconds, Avg Loss: 0.11082208730003312\n",
      "Epoch [370/400] validation completed, Avg Validation Loss: 0.12277338323333571\n",
      "Starting epoch 371/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 370 to omniglot_cold_l1.pth\n",
      "Epoch [371/400] completed in 21.87 seconds, Avg Loss: 0.11128600587498796\n",
      "Epoch [371/400] validation completed, Avg Validation Loss: 0.1140361160280243\n",
      "Starting epoch 372/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 371 to omniglot_cold_l1.pth\n",
      "Epoch [372/400] completed in 21.88 seconds, Avg Loss: 0.10957963994804247\n",
      "Epoch [372/400] validation completed, Avg Validation Loss: 0.12430307398279829\n",
      "Starting epoch 373/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 372 to omniglot_cold_l1.pth\n",
      "Epoch [373/400] completed in 21.91 seconds, Avg Loss: 0.10990597752561747\n",
      "Epoch [373/400] validation completed, Avg Validation Loss: 0.11710561787889849\n",
      "Starting epoch 374/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 373 to omniglot_cold_l1.pth\n",
      "Epoch [374/400] completed in 21.92 seconds, Avg Loss: 0.11615108982621392\n",
      "Epoch [374/400] validation completed, Avg Validation Loss: 0.10170621953664287\n",
      "Starting epoch 375/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 374 to omniglot_cold_l1.pth\n",
      "Epoch [375/400] completed in 21.86 seconds, Avg Loss: 0.11499916911433058\n",
      "Epoch [375/400] validation completed, Avg Validation Loss: 0.10586058889185229\n",
      "Starting epoch 376/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 375 to omniglot_cold_l1.pth\n",
      "Epoch [376/400] completed in 21.86 seconds, Avg Loss: 0.11103439721286543\n",
      "Epoch [376/400] validation completed, Avg Validation Loss: 0.11442971887487557\n",
      "Starting epoch 377/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 376 to omniglot_cold_l1.pth\n",
      "Epoch [377/400] completed in 21.87 seconds, Avg Loss: 0.10924289054583666\n",
      "Epoch [377/400] validation completed, Avg Validation Loss: 0.13036108476620528\n",
      "Starting epoch 378/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 377 to omniglot_cold_l1.pth\n",
      "Epoch [378/400] completed in 21.86 seconds, Avg Loss: 0.11241534201443688\n",
      "Epoch [378/400] validation completed, Avg Validation Loss: 0.09252465059680323\n",
      "Starting epoch 379/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 378 to omniglot_cold_l1.pth\n",
      "Epoch [379/400] completed in 21.91 seconds, Avg Loss: 0.12456109845810685\n",
      "Epoch [379/400] validation completed, Avg Validation Loss: 0.11510841139862614\n",
      "Starting epoch 380/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 379 to omniglot_cold_l1.pth\n",
      "Epoch [380/400] completed in 22.02 seconds, Avg Loss: 0.11817422168221602\n",
      "Epoch [380/400] validation completed, Avg Validation Loss: 0.111095538422946\n",
      "Starting epoch 381/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 380 to omniglot_cold_l1.pth\n",
      "Epoch [381/400] completed in 21.89 seconds, Avg Loss: 0.1132141814744177\n",
      "Epoch [381/400] validation completed, Avg Validation Loss: 0.12931204190657986\n",
      "Starting epoch 382/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 381 to omniglot_cold_l1.pth\n",
      "Epoch [382/400] completed in 21.86 seconds, Avg Loss: 0.10763463770493495\n",
      "Epoch [382/400] validation completed, Avg Validation Loss: 0.10550043116053266\n",
      "Starting epoch 383/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 382 to omniglot_cold_l1.pth\n",
      "Epoch [383/400] completed in 21.86 seconds, Avg Loss: 0.1128562852078356\n",
      "Epoch [383/400] validation completed, Avg Validation Loss: 0.11232095037496859\n",
      "Starting epoch 384/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 383 to omniglot_cold_l1.pth\n",
      "Epoch [384/400] completed in 21.87 seconds, Avg Loss: 0.10436420990077179\n",
      "Epoch [384/400] validation completed, Avg Validation Loss: 0.10574644107011057\n",
      "Starting epoch 385/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 384 to omniglot_cold_l1.pth\n",
      "Epoch [385/400] completed in 21.86 seconds, Avg Loss: 0.1089433512981396\n",
      "Epoch [385/400] validation completed, Avg Validation Loss: 0.13101451777883114\n",
      "Starting epoch 386/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 385 to omniglot_cold_l1.pth\n",
      "Epoch [386/400] completed in 21.88 seconds, Avg Loss: 0.11625551987316243\n",
      "Epoch [386/400] validation completed, Avg Validation Loss: 0.11202364559135129\n",
      "Starting epoch 387/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 386 to omniglot_cold_l1.pth\n",
      "Epoch [387/400] completed in 21.86 seconds, Avg Loss: 0.11514976121146571\n",
      "Epoch [387/400] validation completed, Avg Validation Loss: 0.11125018468667422\n",
      "Starting epoch 388/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 387 to omniglot_cold_l1.pth\n",
      "Epoch [388/400] completed in 21.86 seconds, Avg Loss: 0.10482515203035321\n",
      "Epoch [388/400] validation completed, Avg Validation Loss: 0.10358376819039544\n",
      "Starting epoch 389/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 388 to omniglot_cold_l1.pth\n",
      "Epoch [389/400] completed in 21.87 seconds, Avg Loss: 0.10748073952041629\n",
      "Epoch [389/400] validation completed, Avg Validation Loss: 0.11319195223791946\n",
      "Starting epoch 390/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 389 to omniglot_cold_l1.pth\n",
      "Epoch [390/400] completed in 21.94 seconds, Avg Loss: 0.10504461704822611\n",
      "Epoch [390/400] validation completed, Avg Validation Loss: 0.11046427305066778\n",
      "Starting epoch 391/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 390 to omniglot_cold_l1.pth\n",
      "Epoch [391/400] completed in 21.88 seconds, Avg Loss: 0.1025228488743921\n",
      "Epoch [391/400] validation completed, Avg Validation Loss: 0.12663737113677687\n",
      "Starting epoch 392/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 391 to omniglot_cold_l1.pth\n",
      "Epoch [392/400] completed in 21.89 seconds, Avg Loss: 0.11262460162262779\n",
      "Epoch [392/400] validation completed, Avg Validation Loss: 0.1210618871414373\n",
      "Starting epoch 393/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 392 to omniglot_cold_l1.pth\n",
      "Epoch [393/400] completed in 21.89 seconds, Avg Loss: 0.11078284459173186\n",
      "Epoch [393/400] validation completed, Avg Validation Loss: 0.10644528011400853\n",
      "Starting epoch 394/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 393 to omniglot_cold_l1.pth\n",
      "Epoch [394/400] completed in 21.96 seconds, Avg Loss: 0.11207169599153778\n",
      "Epoch [394/400] validation completed, Avg Validation Loss: 0.11421519827337996\n",
      "Starting epoch 395/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 394 to omniglot_cold_l1.pth\n",
      "Epoch [395/400] completed in 21.83 seconds, Avg Loss: 0.11018124408250259\n",
      "Epoch [395/400] validation completed, Avg Validation Loss: 0.10721709413994704\n",
      "Starting epoch 396/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 395 to omniglot_cold_l1.pth\n",
      "Epoch [396/400] completed in 21.83 seconds, Avg Loss: 0.11297915158562424\n",
      "Epoch [396/400] validation completed, Avg Validation Loss: 0.11247785581696418\n",
      "Starting epoch 397/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 396 to omniglot_cold_l1.pth\n",
      "Epoch [397/400] completed in 21.83 seconds, Avg Loss: 0.1119765490601378\n",
      "Epoch [397/400] validation completed, Avg Validation Loss: 0.11463961272590584\n",
      "Starting epoch 398/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 397 to omniglot_cold_l1.pth\n",
      "Epoch [398/400] completed in 21.81 seconds, Avg Loss: 0.10698972957993834\n",
      "Epoch [398/400] validation completed, Avg Validation Loss: 0.11533298052006191\n",
      "Starting epoch 399/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 398 to omniglot_cold_l1.pth\n",
      "Epoch [399/400] completed in 21.82 seconds, Avg Loss: 0.1118768803806098\n",
      "Epoch [399/400] validation completed, Avg Validation Loss: 0.09897586907590589\n",
      "Starting epoch 400/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch 399 to omniglot_cold_l1.pth\n",
      "Epoch [400/400] completed in 21.82 seconds, Avg Loss: 0.11489953047572828\n",
      "Epoch [400/400] validation completed, Avg Validation Loss: 0.12032358117041088\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape\n",
    "input_shape = (1, 28, 28)\n",
    "\n",
    "# Create an instance of Gaussian Diffusion model\n",
    "model = ColdDiffusionModel(input_shape).to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "# Define the number of epochs and loss weights\n",
    "num_epochs = 400\n",
    "\n",
    "# Filename\n",
    "filename = \"omniglot_cold_l1.pth\"\n",
    "\n",
    "# Load the model training checkpoint\n",
    "start_epoch = load_checkpoint(model, optimizer, filename)\n",
    "    \n",
    "print(f\"The training ended in epoch number: {start_epoch}\")\n",
    "\n",
    "# Train the model\n",
    "trained_model = train(model, optimizer, train_loader, device, start_epoch, num_epochs, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8281e2-8bbd-4fbc-9ea9-329781794ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from omniglot_cold_l1.pth, resuming training from epoch 399\n",
      "The training ended in epoch number: 400\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape\n",
    "input_shape = (1, 28, 28)\n",
    "\n",
    "#define filename\n",
    "filename = \"omniglot_cold_l1.pth\"\n",
    "\n",
    "# Example usage\n",
    "model = ColdDiffusionModel(input_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "start_epoch = load_checkpoint(model, optimizer, filename)\n",
    "print(f\"The training ended in epoch number: {start_epoch+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177fea68-4883-4633-a668-868b07bd038e",
   "metadata": {},
   "source": [
    "## Sampling according to Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b8b8c-72d5-41d2-bdbb-81cfcf652d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the necessary parameters and variables\n",
    "T = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "beta = torch.linspace(beta_start, beta_end, T)\n",
    "alpha = 1 - beta\n",
    "alpha = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "sampled_data = {}\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx in range(32):\n",
    "        x = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "        for s in range(T-1, 0, -1):\n",
    "            t = torch.tensor([s] * x.size(0), dtype=torch.long).to(device)\n",
    "            x_hat = model.decoder(x, t)\n",
    "            z_hat = (1.0/torch.sqrt(1-alpha[s]))* (x - torch.sqrt(alpha[s]) * x_hat) \n",
    "            x = torch.sqrt(alpha[s-1]) * x_hat + torch.sqrt(1-alpha[s-1]) * z_hat\n",
    "            \n",
    "        # Reverse normalization\n",
    "        x = x * 0.5 + 0.5\n",
    "        x = (x.clamp(0, 1) * 255).type(torch.uint8)\n",
    "            \n",
    "        # Store the sampled images\n",
    "        for i in range(x.size(0)):\n",
    "            sampled_data[batch_idx * batch_size + i] = {\n",
    "                'sampled': x[i].cpu()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8f6ba-0c1e-4aad-8470-2710fb1e006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the dictionary to a .pt file\n",
    "torch.save(sampled_data, 'omniglot_cold_l1_alg1.pt')\n",
    "\n",
    "print(\"Sampled data saved to 'omniglot_cold_l1_alg1.pt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396ae46-c395-450b-ae29-b2c87d58c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved data\n",
    "sampled_data = torch.load('omniglot_cold_l1_alg1.pt')\n",
    "\n",
    "# Number of images to display in the grid\n",
    "num_images = 25\n",
    "\n",
    "# Get random indices\n",
    "random_indices = np.random.choice(len(sampled_data), num_images, replace=False)\n",
    "\n",
    "# Initialize the plot\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "\n",
    "# Loop through the images and plot them\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    sampled_image = sampled_data[random_indices[i]]['sampled']\n",
    "    sampled_image = sampled_image.cpu().numpy().transpose(1, 2, 0)\n",
    "    ax.imshow(sampled_image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"Random Sampled Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3d4b70c-b783-441b-b895-c1cf77a302d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(sampled_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bbae7a-4880-4b91-9352-19588a5bb737",
   "metadata": {},
   "source": [
    "## Sampling according to Algorithm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40198a55-dfcc-4a13-82bb-2a96362db74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the necessary parameters and variables\n",
    "T = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "beta = torch.linspace(beta_start, beta_end, T)\n",
    "alpha = 1 - beta\n",
    "alpha = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "sampled_data = {}\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx in range(32):\n",
    "        x = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "        for s in range(T-1, 0, -1):\n",
    "            t = torch.tensor([s] * x.size(0), dtype=torch.long).to(device)\n",
    "            x_hat = model.decoder(x, t)\n",
    "            z_hat = (1.0/torch.sqrt(1-alpha[s]))* (x - torch.sqrt(alpha[s]) * x_hat)\n",
    "            D_s_minus_one = torch.sqrt(alpha[s-1]) * x_hat + torch.sqrt(1-alpha[s-1]) * z_hat\n",
    "            D_s = torch.sqrt(alpha[s]) * x_hat + torch.sqrt(1-alpha[s]) * z_hat\n",
    "            x = x - D_s + D_s_minus_one\n",
    "            \n",
    "        # Reverse normalization\n",
    "        x = x * 0.5 + 0.5\n",
    "        x = (x.clamp(0, 1) * 255).type(torch.uint8)\n",
    "            \n",
    "        # Store the sampled images\n",
    "        for i in range(x.size(0)):\n",
    "            sampled_data[batch_idx * batch_size + i] = {\n",
    "                'sampled': x[i].cpu()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565a95a-4dd1-40c7-8ed4-2e641d31016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the dictionary to a .pt file\n",
    "torch.save(sampled_data, 'omniglot_cold_l1_alg2.pt')\n",
    "\n",
    "print(\"Sampled data saved to 'omniglot_cold_l1_alg2.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc0c0f-a630-419c-8368-294a1ee01d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved data\n",
    "sampled_data = torch.load('omniglot_cold_l1_alg2.pt')\n",
    "\n",
    "# Number of images to display in the grid\n",
    "num_images = 25\n",
    "\n",
    "# Get random indices\n",
    "random_indices = np.random.choice(len(sampled_data), num_images, replace=False)\n",
    "\n",
    "# Initialize the plot\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "\n",
    "# Loop through the images and plot them\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    sampled_image = sampled_data[random_indices[i]]['sampled']\n",
    "    sampled_image = sampled_image.cpu().numpy().transpose(1, 2, 0)\n",
    "    ax.imshow(sampled_image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"Random Sampled Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81c40e-5808-4d1d-a5bc-c5fdbe3e7b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
